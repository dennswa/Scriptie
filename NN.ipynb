{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import Dense\n",
    "from keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"non-trans_10000_5.csv\") \n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX) = train_test_split(df, test_size=0.2, random_state=42)\n",
    "trainY = trainX['picked_node']\n",
    "testY = testX['picked_node']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1: one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_structured_data(df, train, test):\n",
    "\n",
    "    continuous = ['left_node', 'right_node']\n",
    "    cs = MinMaxScaler()\n",
    "    trainX = cs.fit_transform(train[continuous])\n",
    "    testX = cs.transform(test[continuous])\n",
    "    \n",
    "    colourBin = LabelBinarizer().fit(df['left_colour'])\n",
    "    trainLcolourX = colourBin.transform(train['left_colour'])\n",
    "    testLcolourX = colourBin.transform(test['left_colour'])\n",
    "    trainRcolourX = colourBin.transform(train['right_colour'])\n",
    "    testRcolourX = colourBin.transform(test['right_colour'])\n",
    "    trainX = np.hstack([trainX, trainLcolourX, trainRcolourX])\n",
    "    testX = np.hstack([testX, testLcolourX, testRcolourX])\n",
    "    \n",
    "    return (trainX, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(proc_trainX, proc_testX) = process_structured_data(df, trainX, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(dim, regularizer=None):\n",
    "    \"\"\"Creates a simple two-layer MLP with inputs of the given dimension\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=dim, activation=\"relu\", kernel_regularizer=regularizer))\n",
    "    model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=regularizer))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_model = create_mlp(proc_trainX.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.6473 - accuracy: 0.6258 - val_loss: 0.5868 - val_accuracy: 0.6900\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 0s 39us/step - loss: 0.5078 - accuracy: 0.7869 - val_loss: 0.4252 - val_accuracy: 0.8885\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.3600 - accuracy: 0.9275 - val_loss: 0.3037 - val_accuracy: 0.9470\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.2575 - accuracy: 0.9607 - val_loss: 0.2192 - val_accuracy: 0.9735\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 0s 39us/step - loss: 0.1888 - accuracy: 0.9759 - val_loss: 0.1678 - val_accuracy: 0.9830\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 0s 39us/step - loss: 0.1478 - accuracy: 0.9837 - val_loss: 0.1352 - val_accuracy: 0.9900\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.1219 - accuracy: 0.9862 - val_loss: 0.1139 - val_accuracy: 0.9905\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.1047 - accuracy: 0.9885 - val_loss: 0.1005 - val_accuracy: 0.9900\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 0s 39us/step - loss: 0.0923 - accuracy: 0.9902 - val_loss: 0.0891 - val_accuracy: 0.9910\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 0s 39us/step - loss: 0.0830 - accuracy: 0.9924 - val_loss: 0.0810 - val_accuracy: 0.9915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2a24b5addc8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_model.fit(proc_trainX, trainY, batch_size=16, epochs=10, validation_data=(proc_testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 2: ordinal encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_integer_data(df, train, test):\n",
    "    continuous = ['left_node', 'right_node']\n",
    "    cs = MinMaxScaler()\n",
    "    trainX = cs.fit_transform(train[continuous])\n",
    "    testX = cs.transform(test[continuous])\n",
    "    \n",
    "    colourencoder = OrdinalEncoder().fit(np.array(df['left_colour']).reshape(-1,1))\n",
    "    trainLcolourX = colourencoder.transform(np.array(train['left_colour']).reshape(-1,1))\n",
    "    testLcolourX = colourencoder.transform(np.array(test['left_colour']).reshape(-1,1))\n",
    "    trainRcolourX = colourencoder.transform(np.array(train['right_colour']).reshape(-1,1))\n",
    "    testRcolourX = colourencoder.transform(np.array(test['right_colour']).reshape(-1,1))\n",
    "    trainX = np.hstack([trainX, trainLcolourX, trainRcolourX])\n",
    "    testX = np.hstack([testX, testLcolourX, testRcolourX])\n",
    "    \n",
    "    return (trainX, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(proc_trainX, proc_testX) = process_integer_data(df, trainX, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_model = create_mlp(proc_trainX.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.7008 - accuracy: 0.5450 - val_loss: 0.6814 - val_accuracy: 0.5765\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.6751 - accuracy: 0.5775 - val_loss: 0.6696 - val_accuracy: 0.5605\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.6612 - accuracy: 0.5934 - val_loss: 0.6604 - val_accuracy: 0.6030\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.6529 - accuracy: 0.6140 - val_loss: 0.6527 - val_accuracy: 0.6165\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.6456 - accuracy: 0.6246 - val_loss: 0.6455 - val_accuracy: 0.6285\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.6389 - accuracy: 0.6310 - val_loss: 0.6396 - val_accuracy: 0.6400\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.6320 - accuracy: 0.6403 - val_loss: 0.6341 - val_accuracy: 0.6400\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.6266 - accuracy: 0.6472 - val_loss: 0.6310 - val_accuracy: 0.6400\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.6235 - accuracy: 0.6524 - val_loss: 0.6275 - val_accuracy: 0.6475\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.6210 - accuracy: 0.6503 - val_loss: 0.6257 - val_accuracy: 0.6480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2a24db879c8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_model.fit(proc_trainX, trainY, batch_size=10, epochs=10, validation_data=(proc_testX, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 3: Embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(proc_trainX, proc_testX) = process_integer_data(df, trainX, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.6604 - acc: 0.6054 - val_loss: 0.5512 - val_acc: 0.7290\n",
      "Epoch 2/20\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.4517 - acc: 0.7441 - val_loss: 0.3829 - val_acc: 0.8125\n",
      "Epoch 3/20\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3367 - acc: 0.8660 - val_loss: 0.3016 - val_acc: 0.8645\n",
      "Epoch 4/20\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.2770 - acc: 0.8774 - val_loss: 0.2568 - val_acc: 0.8710\n",
      "Epoch 5/20\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.2364 - acc: 0.8907 - val_loss: 0.2141 - val_acc: 0.9045\n",
      "Epoch 6/20\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.1928 - acc: 0.9220 - val_loss: 0.1736 - val_acc: 0.9410\n",
      "Epoch 7/20\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.1536 - acc: 0.9506 - val_loss: 0.1400 - val_acc: 0.9610\n",
      "Epoch 8/20\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.1260 - acc: 0.9639 - val_loss: 0.1176 - val_acc: 0.9660\n",
      "Epoch 9/20\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.1059 - acc: 0.9746 - val_loss: 0.1006 - val_acc: 0.9785\n",
      "Epoch 10/20\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.0915 - acc: 0.9827 - val_loss: 0.0878 - val_acc: 0.9845\n",
      "Epoch 11/20\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.0806 - acc: 0.9850 - val_loss: 0.0785 - val_acc: 0.9905\n",
      "Epoch 12/20\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.0723 - acc: 0.9879 - val_loss: 0.0711 - val_acc: 0.9920\n",
      "Epoch 13/20\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.0656 - acc: 0.9908 - val_loss: 0.0656 - val_acc: 0.9920\n",
      "Epoch 14/20\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.0609 - acc: 0.9912 - val_loss: 0.0603 - val_acc: 0.9935\n",
      "Epoch 15/20\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0565 - acc: 0.9915 - val_loss: 0.0564 - val_acc: 0.9930\n",
      "Epoch 16/20\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0530 - acc: 0.9914 - val_loss: 0.0532 - val_acc: 0.9935\n",
      "Epoch 17/20\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0497 - acc: 0.9916 - val_loss: 0.0501 - val_acc: 0.9930\n",
      "Epoch 18/20\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.0475 - acc: 0.9915 - val_loss: 0.0487 - val_acc: 0.9925\n",
      "Epoch 19/20\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0457 - acc: 0.9911 - val_loss: 0.0461 - val_acc: 0.9925\n",
      "Epoch 20/20\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0432 - acc: 0.9927 - val_loss: 0.0444 - val_acc: 0.9940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2a24de28d08>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def emb(n):\n",
    "\n",
    "    embedding_size = int(np.ceil(n/2))\n",
    "    vocab  = n + 1\n",
    "\n",
    "    model1 = Sequential()\n",
    "    model1.add(Embedding(vocab ,embedding_size, input_length=1))\n",
    "    model1.add(Reshape(target_shape=(embedding_size,)))\n",
    "\n",
    "    model2 = Sequential()\n",
    "    model2.add(Embedding(vocab ,embedding_size, input_length=1))\n",
    "    model2.add(Reshape(target_shape=(embedding_size,)))\n",
    "\n",
    "    model_rest = Sequential()\n",
    "    model_rest.add(Dense(2, input_shape=(2,)))\n",
    "\n",
    "    combined = concatenate([model_rest.output, model1.output, model2.output])\n",
    "\n",
    "    x = Dense(8, activation=\"relu\", kernel_initializer='he_normal')(combined)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    full_model = Model(inputs=[model_rest.input, model1.input, model2.input], outputs = x)\n",
    "    full_model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer='adam')\n",
    "    \n",
    "    return full_model\n",
    "\n",
    "emb_model = emb(len(np.unique(proc_trainX[:, 2])))\n",
    "\n",
    "continous = proc_trainX[:, :2]\n",
    "cat1 = proc_trainX[:, 2]\n",
    "cat2 = proc_trainX[:, 3]\n",
    "\n",
    "tcontinous = proc_testX[:, :2]\n",
    "tcat1 = proc_testX[:, 2]\n",
    "tcat2 = proc_testX[:, 3]\n",
    "\n",
    "emb_model.fit([continous, cat1, cat2], trainY, epochs=20, batch_size=16, validation_data=([tcontinous, tcat1, tcat2], testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 0s 158us/step - loss: 0.7124 - accuracy: 0.4400 - val_loss: 0.6855 - val_accuracy: 0.5200\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.6574 - accuracy: 0.5863 - val_loss: 0.6343 - val_accuracy: 0.5800\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 0s 60us/step - loss: 0.6094 - accuracy: 0.7788 - val_loss: 0.5829 - val_accuracy: 0.8500\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.5599 - accuracy: 0.8325 - val_loss: 0.5320 - val_accuracy: 0.8500\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.5110 - accuracy: 0.8325 - val_loss: 0.4823 - val_accuracy: 0.8500\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.4650 - accuracy: 0.8350 - val_loss: 0.4377 - val_accuracy: 0.8550\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.4233 - accuracy: 0.8462 - val_loss: 0.3968 - val_accuracy: 0.8600\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.3870 - accuracy: 0.8550 - val_loss: 0.3615 - val_accuracy: 0.8800\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.3558 - accuracy: 0.8612 - val_loss: 0.3318 - val_accuracy: 0.8900\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 0s 72us/step - loss: 0.3289 - accuracy: 0.8825 - val_loss: 0.3069 - val_accuracy: 0.9050\n",
      "198/198 [==============================] - 0s 10us/step\n",
      "#####################################################\n",
      "\n",
      "\n",
      "2 colours accuracy = 0.8636363744735718\n",
      "\n",
      "\n",
      "#####################################################\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 0s 164us/step - loss: 0.6807 - accuracy: 0.6212 - val_loss: 0.6531 - val_accuracy: 0.6850\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.6570 - accuracy: 0.6513 - val_loss: 0.6352 - val_accuracy: 0.7250\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.6358 - accuracy: 0.7425 - val_loss: 0.6142 - val_accuracy: 0.8050\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.6147 - accuracy: 0.7788 - val_loss: 0.5942 - val_accuracy: 0.8100\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.5931 - accuracy: 0.8050 - val_loss: 0.5733 - val_accuracy: 0.8250\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.5708 - accuracy: 0.8075 - val_loss: 0.5514 - val_accuracy: 0.8200\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.5476 - accuracy: 0.8250 - val_loss: 0.5293 - val_accuracy: 0.8300\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.5236 - accuracy: 0.8313 - val_loss: 0.5063 - val_accuracy: 0.8400\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.5003 - accuracy: 0.8350 - val_loss: 0.4831 - val_accuracy: 0.8350\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.4773 - accuracy: 0.8363 - val_loss: 0.4627 - val_accuracy: 0.8300\n",
      "198/198 [==============================] - 0s 5us/step\n",
      "#####################################################\n",
      "\n",
      "\n",
      "3 colours accuracy = 0.8232323527336121\n",
      "\n",
      "\n",
      "#####################################################\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 0s 167us/step - loss: 0.6930 - accuracy: 0.4925 - val_loss: 0.6535 - val_accuracy: 0.5750\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.6685 - accuracy: 0.5462 - val_loss: 0.6339 - val_accuracy: 0.6150\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.6460 - accuracy: 0.5688 - val_loss: 0.6135 - val_accuracy: 0.6150\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.6249 - accuracy: 0.5750 - val_loss: 0.5946 - val_accuracy: 0.6150\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.6041 - accuracy: 0.5775 - val_loss: 0.5757 - val_accuracy: 0.6200\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.5833 - accuracy: 0.6087 - val_loss: 0.5559 - val_accuracy: 0.6400\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.5630 - accuracy: 0.6338 - val_loss: 0.5357 - val_accuracy: 0.6750\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.5437 - accuracy: 0.7025 - val_loss: 0.5189 - val_accuracy: 0.7250\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.5266 - accuracy: 0.7237 - val_loss: 0.5026 - val_accuracy: 0.7400\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 0s 67us/step - loss: 0.5111 - accuracy: 0.7350 - val_loss: 0.4888 - val_accuracy: 0.7450\n",
      "198/198 [==============================] - 0s 10us/step\n",
      "#####################################################\n",
      "\n",
      "\n",
      "4 colours accuracy = 0.7121211886405945\n",
      "\n",
      "\n",
      "#####################################################\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 0s 163us/step - loss: 0.6726 - accuracy: 0.5625 - val_loss: 0.6513 - val_accuracy: 0.6150\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.6565 - accuracy: 0.5900 - val_loss: 0.6360 - val_accuracy: 0.6400\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.6420 - accuracy: 0.6263 - val_loss: 0.6230 - val_accuracy: 0.6700\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.6281 - accuracy: 0.6800 - val_loss: 0.6119 - val_accuracy: 0.7050\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.6148 - accuracy: 0.6925 - val_loss: 0.6000 - val_accuracy: 0.6750\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.6008 - accuracy: 0.6875 - val_loss: 0.5867 - val_accuracy: 0.6900\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.5853 - accuracy: 0.6975 - val_loss: 0.5730 - val_accuracy: 0.7000\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 0s 67us/step - loss: 0.5695 - accuracy: 0.7038 - val_loss: 0.5582 - val_accuracy: 0.7150\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 0s 72us/step - loss: 0.5535 - accuracy: 0.7138 - val_loss: 0.5438 - val_accuracy: 0.7150\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.5378 - accuracy: 0.7125 - val_loss: 0.5295 - val_accuracy: 0.7350\n",
      "198/198 [==============================] - 0s 10us/step\n",
      "#####################################################\n",
      "\n",
      "\n",
      "5 colours accuracy = 0.691919207572937\n",
      "\n",
      "\n",
      "#####################################################\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 0s 161us/step - loss: 0.6927 - accuracy: 0.4825 - val_loss: 0.6781 - val_accuracy: 0.5750\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.6811 - accuracy: 0.5500 - val_loss: 0.6663 - val_accuracy: 0.6100\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.6706 - accuracy: 0.6037 - val_loss: 0.6550 - val_accuracy: 0.6450\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.6604 - accuracy: 0.6288 - val_loss: 0.6436 - val_accuracy: 0.6450\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.6502 - accuracy: 0.6475 - val_loss: 0.6306 - val_accuracy: 0.6800\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.6393 - accuracy: 0.6375 - val_loss: 0.6190 - val_accuracy: 0.7000\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.6273 - accuracy: 0.6575 - val_loss: 0.6048 - val_accuracy: 0.7000\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.6151 - accuracy: 0.6700 - val_loss: 0.5915 - val_accuracy: 0.7250\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.6008 - accuracy: 0.6950 - val_loss: 0.5772 - val_accuracy: 0.7250\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.5855 - accuracy: 0.7362 - val_loss: 0.5601 - val_accuracy: 0.7400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 10us/step\n",
      "#####################################################\n",
      "\n",
      "\n",
      "6 colours accuracy = 0.7676767706871033\n",
      "\n",
      "\n",
      "#####################################################\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 0s 162us/step - loss: 0.7246 - accuracy: 0.5150 - val_loss: 0.7307 - val_accuracy: 0.5200\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.7112 - accuracy: 0.5075 - val_loss: 0.7195 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 0s 72us/step - loss: 0.7004 - accuracy: 0.4750 - val_loss: 0.7094 - val_accuracy: 0.4800\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 0s 82us/step - loss: 0.6899 - accuracy: 0.4863 - val_loss: 0.7000 - val_accuracy: 0.4850\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.6786 - accuracy: 0.5350 - val_loss: 0.6899 - val_accuracy: 0.5100\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 0s 59us/step - loss: 0.6676 - accuracy: 0.5738 - val_loss: 0.6800 - val_accuracy: 0.5250\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.6563 - accuracy: 0.6012 - val_loss: 0.6697 - val_accuracy: 0.5250\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.6442 - accuracy: 0.6075 - val_loss: 0.6597 - val_accuracy: 0.5450\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.6321 - accuracy: 0.6225 - val_loss: 0.6481 - val_accuracy: 0.5700\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 0s 67us/step - loss: 0.6184 - accuracy: 0.6413 - val_loss: 0.6362 - val_accuracy: 0.6100\n",
      "198/198 [==============================] - 0s 10us/step\n",
      "#####################################################\n",
      "\n",
      "\n",
      "7 colours accuracy = 0.5959596037864685\n",
      "\n",
      "\n",
      "#####################################################\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 0s 160us/step - loss: 0.7324 - accuracy: 0.5100 - val_loss: 0.7286 - val_accuracy: 0.4900\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.7020 - accuracy: 0.5375 - val_loss: 0.7058 - val_accuracy: 0.4900\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.6835 - accuracy: 0.5663 - val_loss: 0.6908 - val_accuracy: 0.5100\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.6697 - accuracy: 0.6187 - val_loss: 0.6783 - val_accuracy: 0.5600\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.6578 - accuracy: 0.6562 - val_loss: 0.6670 - val_accuracy: 0.6000\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.6462 - accuracy: 0.6737 - val_loss: 0.6547 - val_accuracy: 0.6300\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.6334 - accuracy: 0.6950 - val_loss: 0.6430 - val_accuracy: 0.6700\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.6199 - accuracy: 0.7212 - val_loss: 0.6287 - val_accuracy: 0.7300\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.6043 - accuracy: 0.7650 - val_loss: 0.6110 - val_accuracy: 0.7400\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.5867 - accuracy: 0.7850 - val_loss: 0.5932 - val_accuracy: 0.7600\n",
      "198/198 [==============================] - 0s 5us/step\n",
      "#####################################################\n",
      "\n",
      "\n",
      "8 colours accuracy = 0.7171717286109924\n",
      "\n",
      "\n",
      "#####################################################\n"
     ]
    }
   ],
   "source": [
    "def evaluate(integer=True, embed=False, ep=10, function='linear'):\n",
    "    for i in range(2, 9):\n",
    "        \n",
    "        data = pd.read_csv(str(function) + '_1000_' + str(i) + '.csv') \n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        (trainX, valX) = train_test_split(df, test_size=0.2, random_state=42)\n",
    "        trainY = trainX['picked_node']\n",
    "        valY = valX['picked_node']\n",
    "        \n",
    "        if integer:\n",
    "            (proc_trainX, proc_valX) = process_integer_data(df, trainX, valX)\n",
    "        else:\n",
    "            (proc_trainX, proc_valX) = process_structured_data(df, trainX, valX)\n",
    "        \n",
    "        if embed:\n",
    "            model = emb(len(np.unique(proc_trainX[:, 2])))\n",
    "            continous = proc_trainX[:, :2]\n",
    "            cat1 = proc_trainX[:, 2]\n",
    "            cat2 = proc_trainX[:, 3]\n",
    "\n",
    "            vcontinous = proc_valX[:, :2]\n",
    "            vcat1 = proc_valX[:, 2]\n",
    "            vcat2 = proc_valX[:, 3]\n",
    "\n",
    "            model.fit([continous, cat1, cat2], epochs=ep, batch_size=16, validation_data=([vcontinous, vcat1, vcat2], valY))\n",
    "        else:\n",
    "            model = create_mlp(proc_trainX.shape[1])\n",
    "            model.fit(proc_trainX, trainY, batch_size=10, epochs=ep, validation_data=(proc_valX, valY))\n",
    "            \n",
    "        data = pd.read_csv(str(function) + '_200_' + str(i) + '.csv') \n",
    "        df= pd.DataFrame(data)\n",
    "        \n",
    "        (trainX, testX) = train_test_split(df, test_size=0.01, random_state=42)\n",
    "        trainY = trainX['picked_node']\n",
    "        testY = testX['picked_node']\n",
    "        \n",
    "        if integer:\n",
    "            (proc_testX, proc_test2X) = process_integer_data(df, trainX, valX)\n",
    "        else:\n",
    "            (proc_testX, proc_test2X) = process_structured_data(df, trainX, valX)\n",
    "        \n",
    "        \n",
    "        _, accuracy = model.evaluate(proc_testX, trainY, batch_size=128)\n",
    "        \n",
    "        print('#####################################################\\n\\n')\n",
    "        print(str(i) + \" colours accuracy = \" + str(accuracy))\n",
    "        print('\\n\\n#####################################################')\n",
    "\n",
    "evaluate(integer=False, ep=10,function='non-trans')\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
